{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbfd3f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-14 23:20:51 | app.backend.services.groq | DEBUG | Retrieving Groq API key from Azure Key Vault...\n",
      "2025-07-14 23:20:54 | app.backend.services.groq | DEBUG | Groq API key retrieved.\n"
     ]
    }
   ],
   "source": [
    "from app.backend.core.file_processor import FileProcessor\n",
    "from app.backend.core.analyzer import Analyzer\n",
    "\n",
    "processor = FileProcessor()\n",
    "analyzer = await Analyzer.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9a409a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = \"\"\"\n",
    "Job Summary\n",
    "Our corporate activities are growing rapidly, and we are currently seeking a full-time, office-based Junior Data Engineer to join our Information Technology team. This position will work on a team to accomplish tasks and projects that are instrumental to the company’s success. If you want an exciting career where you use your previous expertise and can develop and grow your career even further, then this is the opportunity for you. \n",
    "\n",
    "\n",
    "Responsibilities\n",
    "\n",
    "Utilize skills in development areas including data warehousing, business intelligence, and databases (Snowflake, ANSI SQL, SQL Server, T-SQL);\n",
    "Support programming/software development using Extract, Transform, and Load (ETL) and Extract, Load and Transform (ELT) tools, (dbt, Azure Data Factory, SSIS);\n",
    "Design, develop, enhance and support business intelligence systems primarily using Microsoft Power BI;\n",
    "Collect, analyze and document user requirements;\n",
    "Participate in software validation process through development, review, and/or execution of test plan/cases/scripts;\n",
    "Create software applications by following software development lifecycle process, which includes requirements gathering, design, development, testing, release, and maintenance;\n",
    "Communicate with team members regarding projects, development, tools, and procedures; and\n",
    "Provide end-user support including setup, installation, and maintenance for applications\n",
    "\n",
    "Qualifications\n",
    "\n",
    "Bachelor's Degree in Computer Science, Data Science, or a related field;\n",
    "Internship experience in Data or Software Engineering;\n",
    "Knowledge of developing dimensional data models and awareness of the advantages and limitations of Star Schema and Snowflake schema designs;\n",
    "Solid ETL development, reporting knowledge based off intricate understanding of business process and measures;\n",
    "Knowledge of Snowflake cloud data warehouse, Fivetran data integration and dbt transformations is preferred;\n",
    "Knowledge of Python is preferred;\n",
    "Knowledge of REST API;\n",
    "Basic knowledge of SQL Server databases is required;\n",
    "Knowledge of C#, Azure development is a bonus; and\n",
    "Excellent analytical, written and oral communication skills.\n",
    "\n",
    "Medpace Overview\n",
    "\n",
    "Medpace is a full-service clinical contract research organization (CRO). We provide Phase I-IV clinical development services to the biotechnology, pharmaceutical and medical device industries. Our mission is to accelerate the global development of safe and effective medical therapeutics through its scientific and disciplined approach. We leverage local regulatory and therapeutic expertise across all major areas including oncology, cardiology, metabolic disease, endocrinology, central nervous system, anti-viral and anti-infective. Headquartered in Cincinnati, Ohio, employing more than 5,000 people across 40+ countries.\n",
    "\n",
    "\n",
    "Why Medpace?\n",
    "\n",
    "People. Purpose. Passion. Make a Difference Tomorrow. Join Us Today.\n",
    "\n",
    " \n",
    "\n",
    "The work we’ve done over the past 30+ years has positively impacted the lives of countless patients and families who face hundreds of diseases across all key therapeutic areas. The work we do today will improve the lives of people living with illness and disease in the future.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e79c865d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-14 23:27:33 | app.backend.services.groq | INFO | Running structured query with function calling using ainvoke...\n",
      "2025-07-14 23:27:35 | app.backend.services.groq | DEBUG | Beautified JSON args:\n",
      "{\n",
      "    \"certificate\": [],\n",
      "    \"domain\": \"Information Technology\",\n",
      "    \"educational_requirements\": [{\n",
      "        \"fields\": [\"Computer Science\", \"Data Science\"],\n",
      "        \"level\": \"Bachelor's\"\n",
      "    }],\n",
      "    \"employment_type\": \"Full-time\",\n",
      "    \"experience\": [\"Internship experience in Data or Software Engineering\"],\n",
      "    \"ideal_candidate_summary\": \"A Junior Data Engineer with a strong foundation in data warehousing, business intelligence, and databases, and excellent analytical, written, and oral communication skills.\",\n",
      "    \"job_level\": \"Junior\",\n",
      "    \"job_title\": \"Junior Data Engineer\",\n",
      "    \"location_requirement\": \"Office-based\",\n",
      "    \"responsibilities\": [\"Utilize skills in development areas including data warehousing, business intelligence, and databases (Snowflake, ANSI SQL, SQL Server, T-SQL)\", \"Support programming/software development using Extract, Transform, and Load (ETL) and Extract, Load and Transform (ELT) tools, (dbt, Azure Data Factory, SSIS)\", \"Design, develop, enhance and support business intelligence systems primarily using Microsoft Power BI\", \"Collect, analyze and document user requirements\", \"Participate in software validation process through development, review, and/or execution of test plan/cases/scripts\", \"Create software applications by following software development lifecycle process, which includes requirements gathering, design, development, testing, release, and maintenance\", \"Communicate with team members regarding projects, development, tools, and procedures\", \"Provide end-user support including setup, installation, and maintenance for applications\"],\n",
      "    \"soft_skill\": [\"analytical\", \"written\", \"oral communication\"],\n",
      "    \"technical_skill\": [\"Snowflake\", \"ANSI SQL\", \"SQL Server\", \"T-SQL\", \"dbt\", \"Azure Data Factory\", \"SSIS\", \"Microsoft Power BI\", \"Python\", \"REST API\", \"SQL Server databases\", \"C#\", \"Azure development\"],\n",
      "    \"years_of_experience\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "job_response = await analyzer.analyze_job(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b396c9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-14 23:21:03 | app.backend.core.file_processor | INFO | Extracting text from local file: data/ExampleResume1.pdf\n",
      "2025-07-14 23:21:03 | app.backend.core.file_processor | INFO | Using .PDF parser for file: data/ExampleResume1.pdf\n",
      "2025-07-14 23:21:03 | app.backend.core.file_processor | INFO | Extracting text from 'data/ExampleResume1.pdf' using local PDF parser (pypdf)\n",
      "2025-07-14 23:21:03 | app.backend.services.groq | INFO | Running structured query with function calling using ainvoke...\n",
      "2025-07-14 23:21:06 | app.backend.services.groq | DEBUG | Beautified JSON args:\n",
      "{\n",
      "    \"candidate_name\": \"Hedy Lamarr\",\n",
      "    \"certificate\": [],\n",
      "    \"comment\": \"Hedy Lamarr is a highly skilled and experienced data engineer with a strong educational background in Computer Science and Statistics. She has demonstrated excellent technical skills and the ability to work effectively in various roles.\",\n",
      "    \"education\": [{\n",
      "        \"field\": \"Computer Science, Statistics\",\n",
      "        \"institution\": \"University of North Carolina at Chapel Hill\",\n",
      "        \"level\": \"Bachelor's\",\n",
      "        \"year\": \"2026\"\n",
      "    }],\n",
      "    \"email\": \"hedylamarr@email.edu\",\n",
      "    \"job_recommended\": [\"Data Engineer\"],\n",
      "    \"phone_number\": \"(555)555-5555\",\n",
      "    \"responsibilities\": [],\n",
      "    \"roles\": [{\n",
      "        \"company\": \"Spotify\",\n",
      "        \"summary\": \"Designed and implemented a cumulative aggregated dataset hosted in BigQuery and GCS to unify multiple data pipelines for podcast consumption metadata.\",\n",
      "        \"title\": \"Data Engineer Intern\"\n",
      "    }, {\n",
      "        \"company\": \"UNC Department of Computer Science\",\n",
      "        \"summary\": \"Hosted 10 weekly office hours and graded exams for over 200 students enrolled in Object-Oriented Programming.\",\n",
      "        \"title\": \"Lead Teaching Assistant\"\n",
      "    }, {\n",
      "        \"company\": \"Apple Inc.\",\n",
      "        \"summary\": \"Pioneered a multi-level Tableau dashboard system for Apple Maps, automating project status reporting and KPI monitoring.\",\n",
      "        \"title\": \"Data Engineer Intern\"\n",
      "    }, {\n",
      "        \"company\": \"Comtech Telecommunications\",\n",
      "        \"summary\": \"Built and deployed 8 new front-end features and improvements to the emergency locator web platform within 6 months.\",\n",
      "        \"title\": \"Software Engineer Intern\"\n",
      "    }],\n",
      "    \"soft_skill\": [],\n",
      "    \"technical_skill\": [\"C\", \"Java\", \"JavaScript\", \"Python\", \"R\", \"Scala\", \"SQL\", \"Docker\", \"Flask\", \"Git\", \"Node.js\", \"PyTorch\", \"React.js\", \"REST APIs\", \"Apache Beam/Hadoop/Spark\", \"BigQuery\", \"GCP\", \"Jira\", \"Jenkins\", \"Jupyter\", \"Snowflake\", \"Tableau\"],\n",
      "    \"websites\": [\"linkedin.com/in/hedylamarr111\"],\n",
      "    \"years_of_experience\": 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "resume = await processor.extract_from_file(\"data/ExampleResume1.pdf\")\n",
    "candidate_response = await analyzer.analyze_candidate(resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a122b86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"candidate\": {\"candidate_name\": \"Hedy Lamarr\", \"certificate\": [], \"comment\": \"Hedy Lamarr is a highly skilled candidate with experience in data engineering, software development, and teaching. She has a strong technical background and has worked with various technologies and tools. Her experience in data analysis and modeling is also notable.\", \"education\": [{\"field\": \"Computer Science, Statistics\", \"gpa\": null, \"institution\": \"University of North Carolina at Chapel Hill\", \"level\": \"Bachelor's\", \"year\": \"2026\"}], \"email\": \"hedylamarr@email.edu\", \"job_recommended\": [\"Data Engineer\", \"Software Engineer\"], \"phone_number\": \"(555) 555-5555\", \"responsibilities\": [\"Designed a cumulative aggregated dataset\", \"Implemented a multi-level Tableau dashboard system\", \"Built and deployed new front-end features\", \"Automated backend API test suite\", \"Managed and coordinated support tasks\"], \"roles\": [{\"company\": \"Spotify\", \"summary\": \"Designed a cumulative aggregated dataset hosted in BigQuery and GCS to unify multiple data pipelines for podcast consumption metadata, centralizing data sources and reducing computational overhead for various metrics.\", \"title\": \"Data Engineer Intern\"}, {\"company\": \"UNC Department of Computer Science\", \"summary\": \"Hosting 10 weekly office hours and grading exams for over 200 students enrolled in Object-Oriented Programming, managing and coordinating support tasks for 12 undergraduate teaching assistants.\", \"title\": \"Lead Teaching Assistant\"}, {\"company\": \"Apple Inc.\", \"summary\": \"Pioneered a multi-level Tableau dashboard system for Apple Maps, automating project status reporting and KPI monitoring for 10+ regional sub-teams.\", \"title\": \"Data Engineer Intern\"}, {\"company\": \"Comtech Telecommunications\", \"summary\": \"Built and deployed 8 new front-end features and improvements to the emergency locator web platform within 6 months, automated 100% of the backend API test suite using Node.js and Chai and implemented real-time status monitors for critical APIs.\", \"title\": \"Software Engineer Intern\"}], \"soft_skill\": [], \"technical_skill\": [\"C\", \"Java\", \"JavaScript\", \"Python\", \"R\", \"Scala\", \"SQL\", \"Docker\", \"Flask\", \"Git\", \"Node.js\", \"PyTorch\", \"React.js\", \"REST APIs\", \"Apache Beam/Hadoop/Spark\", \"BigQuery\", \"GCP\", \"Jira\", \"Jenkins\", \"Jupyter\", \"Snowflake\", \"Tableau\"], \"websites\": [\"linkedin.com/in/hedylamarr111\"], \"years_of_experience\": 2.5}, \"job\": {\"certificate\": [], \"domain\": \"Healthcare\", \"educational_requirements\": [{\"fields\": [\"Artificial Intelligence\", \"Computer Science\", \"Data Science\"], \"level\": \"Bachelor's\"}], \"employment_type\": \"Full-time\", \"experience\": [\"1+ year post-graduate experience implementing and fine-tuning Large Language Models or interactive AI applications\"], \"ideal_candidate_summary\": \"A professional with a background in data science and/or computer science with experience working with AI tools for interactive AI applications across various IT systems\", \"job_level\": \"Mid\", \"job_title\": \"Artificial Intelligence Engineer\", \"location_requirement\": \"Cincinnati\", \"responsibilities\": [\"Design, implement, and deploy machine learning models and systems\", \"Research, develop, and implement machine learning algorithms and models\", \"Collect, preprocess, and curate large datasets required for training generative models\"], \"soft_skill\": [\"Excellent communication skills\", \"Analytical thinker with great attention to detail\"], \"technical_skill\": [\"Python\", \"TensorFlow\", \"PyTorch\", \"NLP\", \"LLM\", \"IA\"], \"years_of_experience\": 1}}\n",
      "876.25\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "combined_input = {\n",
    "    \"candidate\": candidate_response,\n",
    "    \"job\": job_response\n",
    "}\n",
    "combined_input_str = json.dumps(combined_input)\n",
    "print(combined_input_str)\n",
    "print(len(combined_input_str)/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45d09813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-14 23:27:50 | app.backend.services.groq | INFO | Running structured query with function calling using ainvoke...\n",
      "2025-07-14 23:27:53 | app.backend.services.groq | DEBUG | Beautified JSON args:\n",
      "{\n",
      "    \"certificate\": {\n",
      "        \"comment\": \"The candidate does not have any certificates, and the job does not require any specific certificates. Therefore, the score is 0 as there are no certificates to evaluate.\",\n",
      "        \"score\": 0\n",
      "    },\n",
      "    \"domain\": {\n",
      "        \"comment\": \"The candidate's domain experience is in Information Technology, specifically in data engineering, which closely aligns with the job's domain in Information Technology and data engineering. The candidate's experience in data engineering and technical skills make them a strong fit in terms of domain.\",\n",
      "        \"score\": 90\n",
      "    },\n",
      "    \"education\": {\n",
      "        \"comment\": \"The candidate has a Bachelor's degree in Computer Science and Statistics, which closely aligns with the job's educational requirements in Computer Science and Data Science. However, the job requires a stronger focus on Data Science, which is not explicitly mentioned in the candidate's education.\",\n",
      "        \"score\": 80\n",
      "    },\n",
      "    \"experience\": {\n",
      "        \"comment\": \"The candidate has 2 years of experience, including internship experience in data engineering roles. While this provides some relevant experience, the job requires at least internship experience in Data or Software Engineering, which the candidate partially meets. However, the specific experience in data warehousing, business intelligence, and databases is limited.\",\n",
      "        \"score\": 60\n",
      "    },\n",
      "    \"gaps\": [\"Limited experience in data warehousing, business intelligence, and specific database management tools\", \"Lack of specific technical skills in Snowflake, ANSI SQL, SQL Server, T-SQL, dbt, Azure Data Factory, SSIS, and Microsoft Power BI\", \"No certificates\", \"Limited direct experience in the specific responsibilities required by the job\"],\n",
      "    \"overall_summary\": \"The candidate, Hedy Lamarr, is a moderately strong match for the Junior Data Engineer position. She has a solid educational background in Computer Science and Statistics, and her technical skills in data engineering are relevant. However, there are gaps in her experience, particularly in data warehousing, business intelligence, and specific technical tools required by the job. Her internship experiences provide a good foundation, but she lacks direct experience in the specific areas required by the job. With some training and development, she could be a strong fit for the role.\",\n",
      "    \"responsibility\": {\n",
      "        \"comment\": \"The candidate's previous responsibilities include data engineering and software engineering internships, which involve designing and implementing data pipelines, hosting office hours, and grading exams. However, the job requires responsibilities in data warehousing, business intelligence, and database management, which the candidate has limited experience in. The candidate's responsibilities are somewhat aligned but not directly comparable to the job's expectations.\",\n",
      "        \"score\": 50\n",
      "    },\n",
      "    \"soft_skill\": {\n",
      "        \"comment\": \"The candidate's soft skills are not explicitly listed, but the job requires analytical, written, and oral communication skills. While the candidate's comment mentions excellent technical skills and the ability to work effectively in various roles, there is no direct evidence of soft skills like analytical or written communication.\",\n",
      "        \"score\": 60\n",
      "    },\n",
      "    \"strengths\": [\"Strong educational background in Computer Science and Statistics\", \"Relevant technical skills in data engineering, including experience with BigQuery, GCP, and Tableau\", \"Experience in data engineering and software engineering internships\"],\n",
      "    \"technical_skill\": {\n",
      "        \"comment\": \"The candidate has a broad range of technical skills, including Python, SQL, and experience with data engineering tools like BigQuery, GCP, and Tableau. However, the job requires specific skills in Snowflake, ANSI SQL, SQL Server, T-SQL, dbt, Azure Data Factory, SSIS, and Microsoft Power BI, which the candidate only partially matches. The candidate lacks experience in Azure development and specific database management tools required by the job.\",\n",
      "        \"score\": 70\n",
      "    },\n",
      "    \"verdict\": \"Moderate match\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "match_response = await analyzer.match(candidate_analysis=candidate_response, job_analysis=job_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "633addaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.0\n"
     ]
    }
   ],
   "source": [
    "def compute_match_score(match_result: dict) -> float:\n",
    "    weights = {\n",
    "        \"education\": 0.20,\n",
    "        \"experience\": 0.25,\n",
    "        \"technical_skill\": 0.25,\n",
    "        \"responsibility\": 0.20,\n",
    "        \"soft_skill\": 0.05,\n",
    "        \"domain\": 0.05,\n",
    "        \"certificate\": 0,\n",
    "    }\n",
    "\n",
    "    total_score = 0\n",
    "    for key, weight in weights.items():\n",
    "        score = match_result.get(key, {}).get(\"score\", 0)\n",
    "        total_score += score * weight\n",
    "\n",
    "    return round(total_score, 2)\n",
    "\n",
    "print(compute_match_score(match_response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "058d36eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-07 00:38:58 | app.backend.services.groq | DEBUG | Retrieving Groq API key from Azure Key Vault...\n",
      "2025-07-07 00:39:01 | app.backend.services.groq | DEBUG | Groq API key retrieved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x00000255A5E7B1C0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-07 00:39:01 | app.backend.services.groq | INFO | Calling Groq model 'llama3-70b-8192' using ainvoke...\n",
      "The total area of the United Kingdom (UK) is approximately 243,610 square kilometers (93,625 square miles). This includes:\n",
      "\n",
      "* England: 130,279 km² (50,261 sq mi)\n",
      "* Scotland: 78,772 km² (30,414 sq mi)\n",
      "* Wales: 20,779 km² (8,023 sq mi)\n",
      "* Northern Ireland: 14,160 km² (5,470 sq mi)\n",
      "\n",
      "Note: These figures are approximate and may vary slightly depending on the source.\n"
     ]
    }
   ],
   "source": [
    "from app.backend.services.factory import AIServiceFactory\n",
    "\n",
    "service = await AIServiceFactory.create_service()\n",
    "response = await service.query(\"What is the area of the UK?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65be11bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are an expert HR recruiter and resume screener. Your task is to extract relevant information from a resume and organize it into structured categories using the format below.\n",
    "\n",
    "---\n",
    "\n",
    "**Categories**:\n",
    "\n",
    "1. **Synopsis** - A personal summary, description, or “about me” section.  \n",
    "2. **Experience** - Includes jobs/internships under `<job>` and standalone projects under `<project>`.  \n",
    "3. **Education** - Each degree appears under a `<degreeEntry>` with optional GPA and graduation year.  \n",
    "4. **Skills** - Divided into technical and non-technical.\n",
    "\n",
    "---\n",
    "\n",
    "**Important Instructions**:\n",
    "- If no synopsis is present, insert the word `Unknown` in the `<synopsis>` tag.\n",
    "- Do **not** invent or infer missing information. Only extract what is explicitly present.\n",
    "- Use the exact XML structure and tag names provided.\n",
    "- All durations must use time units (e.g., `\"3 months\"`, `\"2 years\"`).\n",
    "- Only include UTF-8 characters. Strip bullets, markdown, or decorative formatting.\n",
    "    - If only a single month is present in the date range, the duration is `\"1 month\"`\n",
    "    - For reference, `\"Present\"` in a job duration refers to {date.today()}\n",
    "\n",
    "---\n",
    "\n",
    "**Format your output as follows**:\n",
    "\n",
    "```xml\n",
    "<resume>\n",
    "    <synopsis>\n",
    "        INSERT SYNOPSIS INFORMATION HERE\n",
    "    </synopsis>\n",
    "    <experience>\n",
    "        <job>\n",
    "            <company>\n",
    "                INSERT COMPANY NAME\n",
    "            </company>\n",
    "            <duration>\n",
    "                INSERT JOB DURATION\n",
    "            </duration>\n",
    "            <description>\n",
    "                INSERT JOB DESCRIPTION\n",
    "            </description>\n",
    "        </job>\n",
    "        <!-- Repeat <job> as needed -->\n",
    "\n",
    "        <project>\n",
    "            <name>\n",
    "                INSERT PROJECT NAME\n",
    "            </name>\n",
    "            <duration>\n",
    "                INSERT PROJECT DURATION (if available)\n",
    "            </duration>\n",
    "            <description>\n",
    "                INSERT PROJECT DESCRIPTION\n",
    "            </description>\n",
    "        </project>\n",
    "        <!-- Repeat <project> as needed -->\n",
    "    </experience>\n",
    "    <education>\n",
    "        <degreeEntry>\n",
    "            <university>\n",
    "                INSERT UNIVERSITY NAME\n",
    "            </university>\n",
    "            <degree>\n",
    "                <level>\n",
    "                    INSERT DEGREE LEVEL (e.g., Doctorate, Masters, Baccalaureate)\n",
    "                </level>\n",
    "                <name>\n",
    "                    INSERT DEGREE NAME (e.g., Computer Science)\n",
    "                </name>\n",
    "            </degree>\n",
    "            <graduationYear>\n",
    "                INSERT GRADUATION YEAR (if available)\n",
    "            </graduationYear>\n",
    "            <gpa>\n",
    "                INSERT GPA (if available)\n",
    "            </gpa>\n",
    "        </degreeEntry>\n",
    "        <!-- Repeat <degreeEntry> as needed -->\n",
    "    </education>\n",
    "    <skills>\n",
    "        <technical>\n",
    "            <software>\n",
    "                LIST SOFTWARE SKILLS\n",
    "            </software>\n",
    "            <languages>\n",
    "                LIST PROGRAMMING LANGUAGES\n",
    "            </languages>\n",
    "            <frameworks>\n",
    "                LIST FRAMEWORKS\n",
    "            </frameworks>\n",
    "            <tools>\n",
    "                LIST TECHNICAL TOOLS\n",
    "            </tools>\n",
    "        </technical>\n",
    "        <nontechnical>\n",
    "            LIST NON-TECHNICAL SKILLS\n",
    "        </nontechnical>\n",
    "    </skills>\n",
    "</resume>\n",
    "\n",
    "---\n",
    "\n",
    "You will now be given a resume in plain text. Extract and organize the information as described above.\n",
    "**Resume**:  \n",
    "{resume}\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
