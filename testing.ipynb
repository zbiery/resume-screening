{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfd3f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-07 00:02:23 | app.backend.core.file_processor | INFO | Extracting text from local file: data/ZacharyBiery_CV_2024.docx\n",
      "2025-07-07 00:02:23 | app.backend.core.file_processor | INFO | Using .DOCX parser for file: data/ZacharyBiery_CV_2024.docx\n",
      "2025-07-07 00:02:23 | app.backend.core.file_processor | INFO | Extracting text from 'data/ZacharyBiery_CV_2024.docx' using local Docx parser (python-docx)\n",
      "2025-07-07 00:02:23 | app.backend.services.groq | DEBUG | Retrieving Groq API key from Azure Key Vault...\n",
      "2025-07-07 00:02:26 | app.backend.services.groq | DEBUG | Groq API key retrieved.\n",
      "2025-07-07 00:02:26 | app.backend.services.groq | INFO | Running structured function-calling query...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zbier\\source\\repos\\resume-screening\\app\\backend\\services\\groq.py:139: LangChainDeprecationWarning: The method `BaseChatModel.predict_messages` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  completion = self.llm.predict_messages(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-07 00:02:29 | app.backend.services.groq | DEBUG | Raw function call arguments: {\"candidate_name\":\"Zachary Biery\",\"certificate\":[],\"comment\":\"Zachary Biery is a highly skilled data science professional with experience in machine learning, data analytics, and software development. He has a strong educational background with a GPA of 4.0 and is expected to complete his Master's in Business Analytics in 2025.\",\"education\":[{\"field\":\"Business Analytics\",\"gpa\":null,\"institution\":\"University of Cincinnati\",\"level\":\"Master's\",\"year\":\"2025\"},{\"field\":\"Business Analytics\",\"gpa\":\"4.0\",\"institution\":\"University of Cincinnati\",\"level\":\"Bachelor's\",\"year\":\"2024\"}],\"email\":\"bieryzt@mail.uc.edu\",\"job_recommended\":[\"Data Engineer\",\"Business Intelligence Analyst\"],\"phone_number\":\"(513) 491-2255\",\"responsibilities\":[\"Train and implement NLP machine learning models\",\"Create multi-class classification models\",\"Develop full-stack software\",\"Automate internal workflows\",\"Develop Power BI reports\"],\"roles\":[{\"company\":\"Medpace\",\"summary\":\"Trained and implemented NLP machine learning models, created multi-class classification models, and developed full-stack software.\",\"title\":\"Data Science Intern\"},{\"company\":\"Toyota North America\",\"summary\":\"Assisted in the development of an interactive UI, created complex tables and views in SQL Server Management Studio, and developed a mobile application for plant audits and part investigations.\",\"title\":\"Systems \\u0026 Business Intelligence Intern\"},{\"company\":\"Kroger\",\"summary\":\"Built interactive dashboards and visuals, used ETL best practices to query and transform large data sets, and assisted in the development of data remediation systems.\",\"title\":\"Data Analyst Intern\"}],\"soft_skill\":[],\"technical_skill\":[\"Python\",\"R\",\"SQL\",\"C++\",\"C#\",\"HTML\",\"CSS\",\"Tableau\",\"PowerBI\",\"Snowflake\",\"dbt\",\"git\",\"MS Power Platform\"],\"websites\":[\"www.linkedin.com/zachary-biery\"],\"years_of_experience\":2.5}\n",
      "2025-07-07 00:02:29 | app.backend.services.groq | DEBUG | Beautified JSON string: {\n",
      "    \"candidate_name\": \"Zachary Biery\",\n",
      "    \"certificate\": [],\n",
      "    \"comment\": \"Zachary Biery is a highly skilled data science professional with experience in machine learning, data analytics, and software development. He has a strong educational background with a GPA of 4.0 and is expected to complete his Master's in Business Analytics in 2025.\",\n",
      "    \"education\": [{\n",
      "        \"field\": \"Business Analytics\",\n",
      "        \"gpa\": null,\n",
      "        \"institution\": \"University of Cincinnati\",\n",
      "        \"level\": \"Master's\",\n",
      "        \"year\": \"2025\"\n",
      "    }, {\n",
      "        \"field\": \"Business Analytics\",\n",
      "        \"gpa\": \"4.0\",\n",
      "        \"institution\": \"University of Cincinnati\",\n",
      "        \"level\": \"Bachelor's\",\n",
      "        \"year\": \"2024\"\n",
      "    }],\n",
      "    \"email\": \"bieryzt@mail.uc.edu\",\n",
      "    \"job_recommended\": [\"Data Engineer\", \"Business Intelligence Analyst\"],\n",
      "    \"phone_number\": \"(513) 491-2255\",\n",
      "    \"responsibilities\": [\"Train and implement NLP machine learning models\", \"Create multi-class classification models\", \"Develop full-stack software\", \"Automate internal workflows\", \"Develop Power BI reports\"],\n",
      "    \"roles\": [{\n",
      "        \"company\": \"Medpace\",\n",
      "        \"summary\": \"Trained and implemented NLP machine learning models, created multi-class classification models, and developed full-stack software.\",\n",
      "        \"title\": \"Data Science Intern\"\n",
      "    }, {\n",
      "        \"company\": \"Toyota North America\",\n",
      "        \"summary\": \"Assisted in the development of an interactive UI, created complex tables and views in SQL Server Management Studio, and developed a mobile application for plant audits and part investigations.\",\n",
      "        \"title\": \"Systems \\u0026 Business Intelligence Intern\"\n",
      "    }, {\n",
      "        \"company\": \"Kroger\",\n",
      "        \"summary\": \"Built interactive dashboards and visuals, used ETL best practices to query and transform large data sets, and assisted in the development of data remediation systems.\",\n",
      "        \"title\": \"Data Analyst Intern\"\n",
      "    }],\n",
      "    \"soft_skill\": [],\n",
      "    \"technical_skill\": [\"Python\", \"R\", \"SQL\", \"C++\", \"C#\", \"HTML\", \"CSS\", \"Tableau\", \"PowerBI\", \"Snowflake\", \"dbt\", \"git\", \"MS Power Platform\"],\n",
      "    \"websites\": [\"www.linkedin.com/zachary-biery\"],\n",
      "    \"years_of_experience\": 2.5\n",
      "}\n",
      "{'candidate_name': 'Zachary Biery', 'certificate': [], 'comment': \"Zachary Biery is a highly skilled data science professional with experience in machine learning, data analytics, and software development. He has a strong educational background with a GPA of 4.0 and is expected to complete his Master's in Business Analytics in 2025.\", 'education': [{'field': 'Business Analytics', 'gpa': None, 'institution': 'University of Cincinnati', 'level': \"Master's\", 'year': '2025'}, {'field': 'Business Analytics', 'gpa': '4.0', 'institution': 'University of Cincinnati', 'level': \"Bachelor's\", 'year': '2024'}], 'email': 'bieryzt@mail.uc.edu', 'job_recommended': ['Data Engineer', 'Business Intelligence Analyst'], 'phone_number': '(513) 491-2255', 'responsibilities': ['Train and implement NLP machine learning models', 'Create multi-class classification models', 'Develop full-stack software', 'Automate internal workflows', 'Develop Power BI reports'], 'roles': [{'company': 'Medpace', 'summary': 'Trained and implemented NLP machine learning models, created multi-class classification models, and developed full-stack software.', 'title': 'Data Science Intern'}, {'company': 'Toyota North America', 'summary': 'Assisted in the development of an interactive UI, created complex tables and views in SQL Server Management Studio, and developed a mobile application for plant audits and part investigations.', 'title': 'Systems & Business Intelligence Intern'}, {'company': 'Kroger', 'summary': 'Built interactive dashboards and visuals, used ETL best practices to query and transform large data sets, and assisted in the development of data remediation systems.', 'title': 'Data Analyst Intern'}], 'soft_skill': [], 'technical_skill': ['Python', 'R', 'SQL', 'C++', 'C#', 'HTML', 'CSS', 'Tableau', 'PowerBI', 'Snowflake', 'dbt', 'git', 'MS Power Platform'], 'websites': ['www.linkedin.com/zachary-biery'], 'years_of_experience': 2.5}\n"
     ]
    }
   ],
   "source": [
    "from app.backend.core.file_processor import FileProcessor\n",
    "from app.backend.core.analyzer import analyze_candidate\n",
    "resume = await FileProcessor().extract_from_file(\"data/ZacharyBiery_CV_2024.docx\")\n",
    "print(analyze_candidate(resume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "058d36eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-07 00:38:58 | app.backend.services.groq | DEBUG | Retrieving Groq API key from Azure Key Vault...\n",
      "2025-07-07 00:39:01 | app.backend.services.groq | DEBUG | Groq API key retrieved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x00000255A5E7B1C0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-07 00:39:01 | app.backend.services.groq | INFO | Calling Groq model 'llama3-70b-8192' using ainvoke...\n",
      "The total area of the United Kingdom (UK) is approximately 243,610 square kilometers (93,625 square miles). This includes:\n",
      "\n",
      "* England: 130,279 km² (50,261 sq mi)\n",
      "* Scotland: 78,772 km² (30,414 sq mi)\n",
      "* Wales: 20,779 km² (8,023 sq mi)\n",
      "* Northern Ireland: 14,160 km² (5,470 sq mi)\n",
      "\n",
      "Note: These figures are approximate and may vary slightly depending on the source.\n"
     ]
    }
   ],
   "source": [
    "from app.backend.services.factory import AIServiceFactory\n",
    "\n",
    "service = await AIServiceFactory.create_service()\n",
    "response = await service.query(\"What is the area of the UK?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58a904b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-06 23:10:22 | app.backend.core.file_processor | INFO | Extracting text from local file: data/ZacharyBiery_CV_2024.pdf\n",
      "2025-07-06 23:10:22 | app.backend.core.file_processor | INFO | Using .PDF parser for file: data/ZacharyBiery_CV_2024.pdf\n",
      "2025-07-06 23:10:22 | app.backend.core.file_processor | INFO | Extracting text from 'data/ZacharyBiery_CV_2024.pdf' using local PDF parser (pypdf)\n",
      "2025-07-06 23:10:26 | app.backend.services.groq | INFO | Running structured function-calling query...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zbier\\source\\repos\\resume-screening\\app\\backend\\services\\groq.py:139: LangChainDeprecationWarning: The method `BaseChatModel.predict_messages` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  completion = self.llm.predict_messages(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'candidate_name': 'Zachary Biery', 'certificate': [], 'comment': '', 'education': [{'degree': 'M.S. Business Analytics', 'institution': 'University of Cincinnati', 'year': 'Expected: April 2025'}, {'degree': 'B.S. Business Analytics', 'gpa': '4.0', 'institution': 'University of Cincinnati', 'year': 'April 2024'}], 'email': 'bieryzt@mail.uc.edu', 'experience': ['Data Science Intern, Commercial Operations – Analytics & Business Intelligence Team at Medpace, Cincinnati OH (May 2024 – Present)', 'Systems & Business Intelligence Intern, Production Control – Systems Team at Toyota North America, Georgetown KY (January 2023 – April 2023)', 'Data Analyst Intern, Enterprise Sourcing – Supplier Solutions Team at Kroger, Cincinnati OH (May 2022 – August 2022)'], 'job_recommended': [], 'phone_number': '(513) 491-2255', 'responsibility': ['Trained & implemented NLP machine learning models using Scikit-Learn & TensorFlow', 'Created multi-class classification models to predict patient biopsy eligibility', 'Responsible for full-stack development of a new contract management software', 'Assisted in developing and implementing back-end architecture to enable enterprise use of document AI in Snowflake', 'Automated various internal workflows using Python & Microsoft Power Automate', 'Assisted in development of Power BI reports for both internal & external audiences', 'Developed a mobile application for plant audits and part investigations using Microsoft PowerApps', 'Fulfilled maintenance and upgrade requests for various Microsoft Access databases', 'Built PowerBI dashboards to track KPIs for cross-dock activity and expedited shipments', 'Developed automated workflow for sequence supplier communications to enhance efficiency across systems', 'Built interactive dashboards and visuals to unlock insights that solve complex data problems', 'Used ETL best practices to query and transform large data sets into reports', 'Assisted in development of data remediation systems using Python', 'Created a standardized process for vendor vetting requirements', 'Created and implemented software solution to assist Sourcing Department in verification of supplier contacts', 'Developed a supplier diversity benchmarking model'], 'soft_skill': [], 'technical_skill': ['Python', 'R', 'SQL', 'C++', 'C#', 'HTML', 'CSS', 'Tableau', 'PowerBI', 'Snowflake', 'dbt', 'git', 'MS Power Platform'], 'websites': ['www.linkedin.com/zachary-biery'], 'years_of_experience': 1.5}\n"
     ]
    }
   ],
   "source": [
    "from app.backend.common.config import AppConfig\n",
    "from app.backend.services.factory import AIServiceFactory\n",
    "from app.backend.services.schema import AIServiceInterface\n",
    "\n",
    "# Define your system prompt and function schema\n",
    "from app.backend.llm.prompts import system_prompt_candidate \n",
    "from app.backend.llm.functions import fn_candidate_analysis\n",
    "\n",
    "from app.backend.core.file_processor import FileProcessor\n",
    "resume = await FileProcessor().extract_from_file(\"data/ZacharyBiery_CV_2024.pdf\")\n",
    "\n",
    "# Main analysis function\n",
    "def analyse_candidate(candidate_data: str) -> dict:\n",
    "    # Create service using factory (Groq or Azure OpenAI based on config)\n",
    "    ai_service: AIServiceInterface = AIServiceFactory.create_service()\n",
    "\n",
    "    # Run structured query\n",
    "    return ai_service.structured_query(\n",
    "        text=candidate_data,\n",
    "        system_prompt=system_prompt_candidate,\n",
    "        functions=fn_candidate_analysis\n",
    "    )\n",
    "\n",
    "print(analyse_candidate(resume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65be11bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are an expert HR recruiter and resume screener. Your task is to extract relevant information from a resume and organize it into structured categories using the format below.\n",
    "\n",
    "---\n",
    "\n",
    "**Categories**:\n",
    "\n",
    "1. **Synopsis** - A personal summary, description, or “about me” section.  \n",
    "2. **Experience** - Includes jobs/internships under `<job>` and standalone projects under `<project>`.  \n",
    "3. **Education** - Each degree appears under a `<degreeEntry>` with optional GPA and graduation year.  \n",
    "4. **Skills** - Divided into technical and non-technical.\n",
    "\n",
    "---\n",
    "\n",
    "**Important Instructions**:\n",
    "- If no synopsis is present, insert the word `Unknown` in the `<synopsis>` tag.\n",
    "- Do **not** invent or infer missing information. Only extract what is explicitly present.\n",
    "- Use the exact XML structure and tag names provided.\n",
    "- All durations must use time units (e.g., `\"3 months\"`, `\"2 years\"`).\n",
    "- Only include UTF-8 characters. Strip bullets, markdown, or decorative formatting.\n",
    "    - If only a single month is present in the date range, the duration is `\"1 month\"`\n",
    "    - For reference, `\"Present\"` in a job duration refers to {date.today()}\n",
    "\n",
    "---\n",
    "\n",
    "**Format your output as follows**:\n",
    "\n",
    "```xml\n",
    "<resume>\n",
    "    <synopsis>\n",
    "        INSERT SYNOPSIS INFORMATION HERE\n",
    "    </synopsis>\n",
    "    <experience>\n",
    "        <job>\n",
    "            <company>\n",
    "                INSERT COMPANY NAME\n",
    "            </company>\n",
    "            <duration>\n",
    "                INSERT JOB DURATION\n",
    "            </duration>\n",
    "            <description>\n",
    "                INSERT JOB DESCRIPTION\n",
    "            </description>\n",
    "        </job>\n",
    "        <!-- Repeat <job> as needed -->\n",
    "\n",
    "        <project>\n",
    "            <name>\n",
    "                INSERT PROJECT NAME\n",
    "            </name>\n",
    "            <duration>\n",
    "                INSERT PROJECT DURATION (if available)\n",
    "            </duration>\n",
    "            <description>\n",
    "                INSERT PROJECT DESCRIPTION\n",
    "            </description>\n",
    "        </project>\n",
    "        <!-- Repeat <project> as needed -->\n",
    "    </experience>\n",
    "    <education>\n",
    "        <degreeEntry>\n",
    "            <university>\n",
    "                INSERT UNIVERSITY NAME\n",
    "            </university>\n",
    "            <degree>\n",
    "                <level>\n",
    "                    INSERT DEGREE LEVEL (e.g., Doctorate, Masters, Baccalaureate)\n",
    "                </level>\n",
    "                <name>\n",
    "                    INSERT DEGREE NAME (e.g., Computer Science)\n",
    "                </name>\n",
    "            </degree>\n",
    "            <graduationYear>\n",
    "                INSERT GRADUATION YEAR (if available)\n",
    "            </graduationYear>\n",
    "            <gpa>\n",
    "                INSERT GPA (if available)\n",
    "            </gpa>\n",
    "        </degreeEntry>\n",
    "        <!-- Repeat <degreeEntry> as needed -->\n",
    "    </education>\n",
    "    <skills>\n",
    "        <technical>\n",
    "            <software>\n",
    "                LIST SOFTWARE SKILLS\n",
    "            </software>\n",
    "            <languages>\n",
    "                LIST PROGRAMMING LANGUAGES\n",
    "            </languages>\n",
    "            <frameworks>\n",
    "                LIST FRAMEWORKS\n",
    "            </frameworks>\n",
    "            <tools>\n",
    "                LIST TECHNICAL TOOLS\n",
    "            </tools>\n",
    "        </technical>\n",
    "        <nontechnical>\n",
    "            LIST NON-TECHNICAL SKILLS\n",
    "        </nontechnical>\n",
    "    </skills>\n",
    "</resume>\n",
    "\n",
    "---\n",
    "\n",
    "You will now be given a resume in plain text. Extract and organize the information as described above.\n",
    "**Resume**:  \n",
    "{resume}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1cf5332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-06 22:26:33 | app.backend.services.groq | INFO | Running structured function-calling query...\n",
      "{'certificate': ['AWS', 'TensorFlow'], 'degree': [\"Bachelor's degree in Computer Science or a related field\"], 'experience': ['machine learning engineer with experience in Python, PyTorch, and MLOps'], 'responsibility': ['model deployment', 'data pipeline design', 'working in a fast-paced, collaborative environment'], 'soft_skill': ['collaboration'], 'technical_skill': ['Python', 'PyTorch', 'MLOps']}\n"
     ]
    }
   ],
   "source": [
    "from app.backend.common.config import AppConfig\n",
    "from app.backend.services.factory import AIServiceFactory\n",
    "from app.backend.services.schema import AIServiceInterface\n",
    "\n",
    "# Define your system prompt and function schema\n",
    "from app.backend.llm.prompts import system_prompt_job  \n",
    "from app.backend.llm.functions import fn_job_analysis     \n",
    "\n",
    "# Main analysis function\n",
    "def analyse_job(job_data: str) -> dict:\n",
    "    # Create service using factory (Groq or Azure OpenAI based on config)\n",
    "    ai_service: AIServiceInterface = AIServiceFactory.create_service()\n",
    "\n",
    "    # Run structured query\n",
    "    return ai_service.structured_query(\n",
    "        text=job_data,\n",
    "        system_prompt=system_prompt_job,\n",
    "        functions=fn_job_analysis\n",
    "    )\n",
    "\n",
    "\n",
    "print(analyse_job(job_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb99f86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'certificate': [], 'degree': [\"Bachelor's degree or higher in Artificial Intelligence, Computer or Data Science, or related field. Master's degree preferred\"], 'experience': ['Implementing and fine-tuning Large Language Models or interactive AI applications (>1 year post-graduate experience)'], 'responsibility': ['Design, implement, and deploy machine learning models and systems to solve complex problems and drive business outcomes;', 'Research, develop, and implement machine learning algorithms and models for tasks such as classification, regression, clustering, anomaly detection, and recommendation systems;', 'Research, develop, and implement AI tools such as NLP, LLM, and IA;', 'Collect, preprocess, and curate large datasets required for training generative models;', 'Experiment with different machine learning techniques and algorithms, including supervised, unsupervised, semi-supervised, reinforcement, and deep learning;', 'Design and optimize machine learning pipelines and workflows, incorporating techniques for data cleaning, feature engineering, model selection, and hyperparameter tuning;', 'Develop scalable and efficient machine learning infrastructure and systems for training, testing, and deploying models in production environments.'], 'soft_skill': ['Excellent communication skills', 'Passion for staying up-to-date with the latest advancements in NLP and AI technologies', 'Analytical thinker with great attention to detail'], 'technical_skill': ['Python', 'TensorFlow', 'PyTorch']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import jsbeautifier\n",
    "\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "from app.backend.common.config import AppConfig\n",
    "\n",
    "# Load app config and secret\n",
    "config = AppConfig()\n",
    "credential = DefaultAzureCredential()\n",
    "secret_client = SecretClient(vault_url=config.keyvault_url, credential=credential)\n",
    "groq_secret = secret_client.get_secret(config.groq_secret_name)\n",
    "\n",
    "# Utility to parse function_call output into JSON\n",
    "def output2json(output: dict) -> dict:\n",
    "    \"\"\"Convert LLM function_call argument string to JSON object.\"\"\"\n",
    "    opts = jsbeautifier.default_options()\n",
    "    raw_args = output.get(\"function_call\", {}).get(\"arguments\", \"\")\n",
    "    return json.loads(jsbeautifier.beautify(raw_args, opts))\n",
    "\n",
    "# Main analysis function\n",
    "def analyse_job(job_data: str) -> dict:\n",
    "    start = time.time()\n",
    "\n",
    "    # Initialize Groq Chat LLM\n",
    "    llm = ChatGroq(\n",
    "        api_key=groq_secret.value,\n",
    "        model=config.groq_model,\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "    # Send message with system and user prompt\n",
    "    completion = llm.predict_messages(\n",
    "        messages=[\n",
    "            SystemMessage(content=system_prompt_job),\n",
    "            HumanMessage(content=job_data)\n",
    "        ],\n",
    "        functions=fn_job_analysis,\n",
    "        function_call=\"auto\"\n",
    "    )\n",
    "\n",
    "    # Parse function call output\n",
    "    output_analysis = completion.additional_kwargs\n",
    "    json_output = output2json(output_analysis)\n",
    "\n",
    "    return json_output\n",
    "\n",
    "\n",
    "print(analyse_job(job_data))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
