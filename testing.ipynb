{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbfd3f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-14 22:10:34 | app.backend.services.groq | DEBUG | Retrieving Groq API key from Azure Key Vault...\n",
      "2025-07-14 22:10:36 | app.backend.services.groq | DEBUG | Groq API key retrieved.\n"
     ]
    }
   ],
   "source": [
    "from app.backend.core.file_processor import FileProcessor\n",
    "from app.backend.core.analyzer import Analyzer\n",
    "\n",
    "processor = FileProcessor()\n",
    "analyzer = await Analyzer.create()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e79c865d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-14 22:10:38 | app.backend.services.groq | INFO | Running structured query with function calling using ainvoke...\n",
      "2025-07-14 22:10:40 | app.backend.services.groq | DEBUG | Beautified JSON args:\n",
      "{\n",
      "    \"certificate\": [],\n",
      "    \"domain\": \"Healthcare\",\n",
      "    \"educational_requirements\": [{\n",
      "        \"fields\": [\"Artificial Intelligence\", \"Computer Science\", \"Data Science\"],\n",
      "        \"level\": \"Bachelor's\"\n",
      "    }],\n",
      "    \"employment_type\": \"Full-time\",\n",
      "    \"experience\": [\"1+ year post-graduate experience implementing and fine-tuning Large Language Models or interactive AI applications\"],\n",
      "    \"ideal_candidate_summary\": \"Passionate about Artificial Intelligence and staying up-to-date with the latest advancements in NLP and AI technologies\",\n",
      "    \"job_level\": \"Mid\",\n",
      "    \"job_title\": \"Artificial Intelligence Engineer\",\n",
      "    \"location_requirement\": \"Cincinnati, Ohio\",\n",
      "    \"responsibilities\": [\"Design, implement, and deploy machine learning models and systems\", \"Research, develop, and implement machine learning algorithms and models\", \"Collect, preprocess, and curate large datasets required for training generative models\", \"Experiment with different machine learning techniques and algorithms\", \"Design and optimize machine learning pipelines and workflows\"],\n",
      "    \"soft_skill\": [\"Excellent communication skills\", \"Analytical thinker with great attention to detail\"],\n",
      "    \"technical_skill\": [\"Python\", \"TensorFlow\", \"PyTorch\", \"NLP\", \"LLM\", \"IA\"],\n",
      "    \"years_of_experience\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "job = \"\"\"\n",
    "Job Summary\n",
    "Do you have a passion for Artificial Intelligence (AI) and are looking to make a difference in how the latest clinical trials progress into the market?\n",
    "\n",
    " \n",
    "\n",
    "Do you have a background in data science and/or computer science with experience working with AI tools for interactive AI applications across various IT systems? \n",
    "\n",
    " \n",
    "\n",
    "If so, we have an exciting opportunity for you at Medpace.\n",
    "\n",
    " \n",
    "\n",
    "We are currently seeking a professional with experience with artificial intelligence (AI) tools such as NLP, LLM, IA etc. This professional will be programming and fine-tuning various AI tools and helping IT teams to implement them into new applications.\n",
    "\n",
    " \n",
    "\n",
    "This professional will work collaboratively across the organization with multiple teams to improve the efficiency of company processes and provide insights and assistance to users.\n",
    "\n",
    "\n",
    "Responsibilities\n",
    "\n",
    "Design, implement, and deploy machine learning models and systems to solve complex problems and drive business outcomes;\n",
    "Research, develop, and implement machine learning algorithms and models for tasks such as classification, regression, clustering, anomaly detection, and recommendation systems;\n",
    "Research, develop, and implement AI tools such as NLP, LLM, and IA;\n",
    "Collect, preprocess, and curate large datasets required for training generative models;\n",
    "Experiment with different machine learning techniques and algorithms, including supervised, unsupervised, semi-supervised, reinforcement, and deep learning;\n",
    "Design and optimize machine learning pipelines and workflows, incorporating techniques for data cleaning, feature engineering, model selection, and hyperparameter tuning; and\n",
    "Develop scalable and efficient machine learning infrastructure and systems for training, testing, and deploying models in production environments.\n",
    "\n",
    "Qualifications\n",
    "\n",
    "Bachelor’s degree or higher in Artificial Intelligence, Computer or Data Science, or related field. Master’s degree preferred;\n",
    "Proven experience implementing and fine-tuning Large Language Models or interactive AI applications (>1 year post-graduate experience);\n",
    "Technical proficiency in programming languages and frameworks commonly used in NLP and AI (e.g., Python, TensorFlow, PyTorch);\n",
    "Preferably several years of experience working with different AI capabilities and showcasing your passion both at work and outside work in the utilization of AI;\n",
    "Excellent communication skills to collaborate effectively with cross-functional teams;\n",
    "A passion for staying up-to-date with the latest advancements in NLP and AI technologies; and\n",
    "Analytical thinker with great attention to detail. \n",
    "\n",
    "Medpace Overview\n",
    "\n",
    "Medpace is a full-service clinical contract research organization (CRO). We provide Phase I-IV clinical development services to the biotechnology, pharmaceutical and medical device industries. Our mission is to accelerate the global development of safe and effective medical therapeutics through its scientific and disciplined approach. We leverage local regulatory and therapeutic expertise across all major areas including oncology, cardiology, metabolic disease, endocrinology, central nervous system, anti-viral and anti-infective. Headquartered in Cincinnati, Ohio, employing more than 5,000 people across 40+ countries.\n",
    "\n",
    "\n",
    "Why Medpace?\n",
    "\n",
    "People. Purpose. Passion. Make a Difference Tomorrow. Join Us Today.\n",
    "\n",
    " \n",
    "\n",
    "The work we’ve done over the past 30+ years has positively impacted the lives of countless patients and families who face hundreds of diseases across all key therapeutic areas. The work we do today will improve the lives of people living with illness and disease in the future.\n",
    "\n",
    " \n",
    "\n",
    "Cincinnati Perks\n",
    "\n",
    "Cincinnati Campus Overview\n",
    "Flexible work environment\n",
    "Competitive PTO packages, starting at 20+ days\n",
    "Competitive compensation and benefits package\n",
    "Company-sponsored employee appreciation events\n",
    "Employee health and wellness initiatives\n",
    "Community involvement with local nonprofit organizations\n",
    "Discounts on local sports games, fitness gyms and attractions\n",
    "Modern, ecofriendly campus with an on-site fitness center\n",
    "Structured career paths with opportunities for professional growth\n",
    "Discounted tuition for UC online programs\n",
    "Awards\n",
    "\n",
    "Named a Top Workplace in 2024 by The Cincinnati Enquirer\n",
    "\n",
    "Recognized by Forbes as one of America's Most Successful Midsize Companies in 2021, 2022, 2023 and 2024\n",
    "Continually recognized with CRO Leadership Awards from Life Science Leader magazine based on expertise, quality, capabilities, reliability, and compatibility\n",
    "\"\"\"\n",
    "job_response = await analyzer.analyze_job(job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b396c9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-14 22:10:49 | app.backend.core.file_processor | INFO | Extracting text from local file: data/ExampleResume1.pdf\n",
      "2025-07-14 22:10:49 | app.backend.core.file_processor | INFO | Using .PDF parser for file: data/ExampleResume1.pdf\n",
      "2025-07-14 22:10:49 | app.backend.core.file_processor | INFO | Extracting text from 'data/ExampleResume1.pdf' using local PDF parser (pypdf)\n",
      "2025-07-14 22:10:50 | app.backend.services.groq | INFO | Running structured query with function calling using ainvoke...\n",
      "2025-07-14 22:10:55 | app.backend.services.groq | DEBUG | Beautified JSON args:\n",
      "{\n",
      "    \"candidate_name\": \"Hedy Lamarr\",\n",
      "    \"certificate\": [],\n",
      "    \"comment\": \"Hedy Lamarr is a highly skilled candidate with experience in data engineering, software engineering, and teaching. She has a strong technical skill set and has worked on various projects, including data analysis and infrastructure optimization.\",\n",
      "    \"education\": [{\n",
      "        \"field\": \"Computer Science, Statistics\",\n",
      "        \"institution\": \"University of North Carolina at Chapel Hill\",\n",
      "        \"level\": \"Bachelor's\",\n",
      "        \"year\": \"2026\"\n",
      "    }],\n",
      "    \"email\": \"hedylamarr@email.edu\",\n",
      "    \"job_recommended\": [\"Data Engineer\", \"Software Engineer\", \"Teaching Assistant\"],\n",
      "    \"phone_number\": \"(555) 555-5555\",\n",
      "    \"responsibilities\": [\"Designed a cumulative aggregated dataset\", \"Implemented the dataset using Scala and Apache Beam APIs\", \"Analyzed hundreds of trending, book-based playlists\", \"Conducted A/B tests to validate targeted audiobook campaigns\", \"Pioneered a multi-level Tableau dashboard system\", \"Streamlined complex data sources in Hive using data wrangling techniques\", \"Evaluated and presented findings and recommendations for data infrastructure optimization\", \"Built and deployed 8 new front-end features and improvements\"],\n",
      "    \"roles\": [{\n",
      "        \"company\": \"Spotify\",\n",
      "        \"summary\": \"Designed a cumulative aggregated dataset hosted in BigQuery and GCS to unify multiple data pipelines for podcast consumption metadata, centralizing data sources and reducing computational overhead for various metrics.\",\n",
      "        \"title\": \"Data Engineer Intern\"\n",
      "    }, {\n",
      "        \"company\": \"UNC Department of Computer Science\",\n",
      "        \"summary\": \"Hosting 10 weekly office hours and grading exams for over 200 students enrolled in Object-Oriented Programming, managing and coordinating support tasks for 12 undergraduate teaching assistants.\",\n",
      "        \"title\": \"Lead Teaching Assistant\"\n",
      "    }, {\n",
      "        \"company\": \"Apple Inc.\",\n",
      "        \"summary\": \"Pioneered a multi-level Tableau dashboard system for Apple Maps, automating project status reporting and KPI monitoring for 10+ regional sub-teams.\",\n",
      "        \"title\": \"Data Engineer Intern\"\n",
      "    }, {\n",
      "        \"company\": \"Comtech Telecommunications\",\n",
      "        \"summary\": \"Built and deployed 8 new front-end features and improvements to the emergency locator web platform within 6 months, automated 100% of the backend API test suite using Node.js and Chai and implemented real-time status monitors for critical APIs.\",\n",
      "        \"title\": \"Software Engineer Intern\"\n",
      "    }],\n",
      "    \"soft_skill\": [],\n",
      "    \"technical_skill\": [\"C\", \"Java\", \"JavaScript\", \"Python\", \"R\", \"Scala\", \"SQL\", \"Docker\", \"Flask\", \"Git\", \"Node.js\", \"PyTorch\", \"React.js\", \"REST APIs\", \"Apache Beam/Hadoop/Spark\", \"BigQuery\", \"GCP\", \"Jira\", \"Jenkins\", \"Jupyter\", \"Snowflake\", \"Tableau\"],\n",
      "    \"websites\": [\"linkedin.com/in/hedylamarr111\"],\n",
      "    \"years_of_experience\": 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "resume = await processor.extract_from_file(\"data/ExampleResume1.pdf\")\n",
    "candidate_response = await analyzer.analyze_candidate(resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a122b86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"candidate\": {\"candidate_name\": \"Hedy Lamarr\", \"certificate\": [], \"comment\": \"Hedy Lamarr is a highly skilled candidate with experience in data engineering, software engineering, and teaching. She has a strong technical skill set and has worked on various projects, including data analysis and infrastructure optimization.\", \"education\": [{\"field\": \"Computer Science, Statistics\", \"institution\": \"University of North Carolina at Chapel Hill\", \"level\": \"Bachelor's\", \"year\": \"2026\"}], \"email\": \"hedylamarr@email.edu\", \"job_recommended\": [\"Data Engineer\", \"Software Engineer\", \"Teaching Assistant\"], \"phone_number\": \"(555) 555-5555\", \"responsibilities\": [\"Designed a cumulative aggregated dataset\", \"Implemented the dataset using Scala and Apache Beam APIs\", \"Analyzed hundreds of trending, book-based playlists\", \"Conducted A/B tests to validate targeted audiobook campaigns\", \"Pioneered a multi-level Tableau dashboard system\", \"Streamlined complex data sources in Hive using data wrangling techniques\", \"Evaluated and presented findings and recommendations for data infrastructure optimization\", \"Built and deployed 8 new front-end features and improvements\"], \"roles\": [{\"company\": \"Spotify\", \"summary\": \"Designed a cumulative aggregated dataset hosted in BigQuery and GCS to unify multiple data pipelines for podcast consumption metadata, centralizing data sources and reducing computational overhead for various metrics.\", \"title\": \"Data Engineer Intern\"}, {\"company\": \"UNC Department of Computer Science\", \"summary\": \"Hosting 10 weekly office hours and grading exams for over 200 students enrolled in Object-Oriented Programming, managing and coordinating support tasks for 12 undergraduate teaching assistants.\", \"title\": \"Lead Teaching Assistant\"}, {\"company\": \"Apple Inc.\", \"summary\": \"Pioneered a multi-level Tableau dashboard system for Apple Maps, automating project status reporting and KPI monitoring for 10+ regional sub-teams.\", \"title\": \"Data Engineer Intern\"}, {\"company\": \"Comtech Telecommunications\", \"summary\": \"Built and deployed 8 new front-end features and improvements to the emergency locator web platform within 6 months, automated 100% of the backend API test suite using Node.js and Chai and implemented real-time status monitors for critical APIs.\", \"title\": \"Software Engineer Intern\"}], \"soft_skill\": [], \"technical_skill\": [\"C\", \"Java\", \"JavaScript\", \"Python\", \"R\", \"Scala\", \"SQL\", \"Docker\", \"Flask\", \"Git\", \"Node.js\", \"PyTorch\", \"React.js\", \"REST APIs\", \"Apache Beam/Hadoop/Spark\", \"BigQuery\", \"GCP\", \"Jira\", \"Jenkins\", \"Jupyter\", \"Snowflake\", \"Tableau\"], \"websites\": [\"linkedin.com/in/hedylamarr111\"], \"years_of_experience\": 2}, \"job\": {\"certificate\": [], \"domain\": \"Healthcare\", \"educational_requirements\": [{\"fields\": [\"Artificial Intelligence\", \"Computer Science\", \"Data Science\"], \"level\": \"Bachelor's\"}], \"employment_type\": \"Full-time\", \"experience\": [\"1+ year post-graduate experience implementing and fine-tuning Large Language Models or interactive AI applications\"], \"ideal_candidate_summary\": \"Passionate about Artificial Intelligence and staying up-to-date with the latest advancements in NLP and AI technologies\", \"job_level\": \"Mid\", \"job_title\": \"Artificial Intelligence Engineer\", \"location_requirement\": \"Cincinnati, Ohio\", \"responsibilities\": [\"Design, implement, and deploy machine learning models and systems\", \"Research, develop, and implement machine learning algorithms and models\", \"Collect, preprocess, and curate large datasets required for training generative models\", \"Experiment with different machine learning techniques and algorithms\", \"Design and optimize machine learning pipelines and workflows\"], \"soft_skill\": [\"Excellent communication skills\", \"Analytical thinker with great attention to detail\"], \"technical_skill\": [\"Python\", \"TensorFlow\", \"PyTorch\", \"NLP\", \"LLM\", \"IA\"], \"years_of_experience\": 1}}\n",
      "967.75\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "combined_input = {\n",
    "    \"candidate\": candidate_response,\n",
    "    \"job\": job_response\n",
    "}\n",
    "combined_input_str = json.dumps(combined_input)\n",
    "print(combined_input_str)\n",
    "print(len(combined_input_str)/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45d09813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-14 22:11:04 | app.backend.services.groq | INFO | Running structured query with function calling using ainvoke...\n",
      "2025-07-14 22:11:08 | app.backend.services.groq | ERROR | Missing function_call or arguments: {}\n",
      "2025-07-14 22:11:08 | app.backend.services.groq | ERROR | Structured Groq ainvoke query failed: No function_call with arguments returned.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No function_call with arguments returned.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m match_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m analyzer\u001b[38;5;241m.\u001b[39mmatch(candidate_analysis\u001b[38;5;241m=\u001b[39mcandidate_response, job_analysis\u001b[38;5;241m=\u001b[39mjob_response)\n",
      "File \u001b[1;32mc:\\Users\\Zbier\\source\\repos\\resume-screening\\app\\backend\\core\\analyzer.py:55\u001b[0m, in \u001b[0;36mAnalyzer.match\u001b[1;34m(self, candidate_analysis, job_analysis)\u001b[0m\n\u001b[0;32m     42\u001b[0m combined_input \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcandidate\u001b[39m\u001b[38;5;124m\"\u001b[39m: candidate_analysis,\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob\u001b[39m\u001b[38;5;124m\"\u001b[39m: job_analysis\n\u001b[0;32m     45\u001b[0m }\n\u001b[0;32m     47\u001b[0m input_text \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou will receive job and candidate information below. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluate the match across all categories according to the instructions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m )\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mai_service\u001b[38;5;241m.\u001b[39mstructured_query(\n\u001b[0;32m     56\u001b[0m     text\u001b[38;5;241m=\u001b[39minput_text,\n\u001b[0;32m     57\u001b[0m     system_prompt\u001b[38;5;241m=\u001b[39msystem_prompt_match,  \n\u001b[0;32m     58\u001b[0m     functions\u001b[38;5;241m=\u001b[39mfn_match\n\u001b[0;32m     59\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Zbier\\source\\repos\\resume-screening\\app\\backend\\services\\groq.py:169\u001b[0m, in \u001b[0;36mGroqService.structured_query\u001b[1;34m(self, text, system_prompt, functions)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m function_call \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m function_call:\n\u001b[0;32m    168\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing function_call or arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39madditional_kwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo function_call with arguments returned.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    171\u001b[0m raw_args \u001b[38;5;241m=\u001b[39m function_call[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    172\u001b[0m beautified \u001b[38;5;241m=\u001b[39m jsbeautifier\u001b[38;5;241m.\u001b[39mbeautify(raw_args)\n",
      "\u001b[1;31mValueError\u001b[0m: No function_call with arguments returned."
     ]
    }
   ],
   "source": [
    "match_response = await analyzer.match(candidate_analysis=candidate_response, job_analysis=job_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "058d36eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-07 00:38:58 | app.backend.services.groq | DEBUG | Retrieving Groq API key from Azure Key Vault...\n",
      "2025-07-07 00:39:01 | app.backend.services.groq | DEBUG | Groq API key retrieved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x00000255A5E7B1C0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-07 00:39:01 | app.backend.services.groq | INFO | Calling Groq model 'llama3-70b-8192' using ainvoke...\n",
      "The total area of the United Kingdom (UK) is approximately 243,610 square kilometers (93,625 square miles). This includes:\n",
      "\n",
      "* England: 130,279 km² (50,261 sq mi)\n",
      "* Scotland: 78,772 km² (30,414 sq mi)\n",
      "* Wales: 20,779 km² (8,023 sq mi)\n",
      "* Northern Ireland: 14,160 km² (5,470 sq mi)\n",
      "\n",
      "Note: These figures are approximate and may vary slightly depending on the source.\n"
     ]
    }
   ],
   "source": [
    "from app.backend.services.factory import AIServiceFactory\n",
    "\n",
    "service = await AIServiceFactory.create_service()\n",
    "response = await service.query(\"What is the area of the UK?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65be11bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are an expert HR recruiter and resume screener. Your task is to extract relevant information from a resume and organize it into structured categories using the format below.\n",
    "\n",
    "---\n",
    "\n",
    "**Categories**:\n",
    "\n",
    "1. **Synopsis** - A personal summary, description, or “about me” section.  \n",
    "2. **Experience** - Includes jobs/internships under `<job>` and standalone projects under `<project>`.  \n",
    "3. **Education** - Each degree appears under a `<degreeEntry>` with optional GPA and graduation year.  \n",
    "4. **Skills** - Divided into technical and non-technical.\n",
    "\n",
    "---\n",
    "\n",
    "**Important Instructions**:\n",
    "- If no synopsis is present, insert the word `Unknown` in the `<synopsis>` tag.\n",
    "- Do **not** invent or infer missing information. Only extract what is explicitly present.\n",
    "- Use the exact XML structure and tag names provided.\n",
    "- All durations must use time units (e.g., `\"3 months\"`, `\"2 years\"`).\n",
    "- Only include UTF-8 characters. Strip bullets, markdown, or decorative formatting.\n",
    "    - If only a single month is present in the date range, the duration is `\"1 month\"`\n",
    "    - For reference, `\"Present\"` in a job duration refers to {date.today()}\n",
    "\n",
    "---\n",
    "\n",
    "**Format your output as follows**:\n",
    "\n",
    "```xml\n",
    "<resume>\n",
    "    <synopsis>\n",
    "        INSERT SYNOPSIS INFORMATION HERE\n",
    "    </synopsis>\n",
    "    <experience>\n",
    "        <job>\n",
    "            <company>\n",
    "                INSERT COMPANY NAME\n",
    "            </company>\n",
    "            <duration>\n",
    "                INSERT JOB DURATION\n",
    "            </duration>\n",
    "            <description>\n",
    "                INSERT JOB DESCRIPTION\n",
    "            </description>\n",
    "        </job>\n",
    "        <!-- Repeat <job> as needed -->\n",
    "\n",
    "        <project>\n",
    "            <name>\n",
    "                INSERT PROJECT NAME\n",
    "            </name>\n",
    "            <duration>\n",
    "                INSERT PROJECT DURATION (if available)\n",
    "            </duration>\n",
    "            <description>\n",
    "                INSERT PROJECT DESCRIPTION\n",
    "            </description>\n",
    "        </project>\n",
    "        <!-- Repeat <project> as needed -->\n",
    "    </experience>\n",
    "    <education>\n",
    "        <degreeEntry>\n",
    "            <university>\n",
    "                INSERT UNIVERSITY NAME\n",
    "            </university>\n",
    "            <degree>\n",
    "                <level>\n",
    "                    INSERT DEGREE LEVEL (e.g., Doctorate, Masters, Baccalaureate)\n",
    "                </level>\n",
    "                <name>\n",
    "                    INSERT DEGREE NAME (e.g., Computer Science)\n",
    "                </name>\n",
    "            </degree>\n",
    "            <graduationYear>\n",
    "                INSERT GRADUATION YEAR (if available)\n",
    "            </graduationYear>\n",
    "            <gpa>\n",
    "                INSERT GPA (if available)\n",
    "            </gpa>\n",
    "        </degreeEntry>\n",
    "        <!-- Repeat <degreeEntry> as needed -->\n",
    "    </education>\n",
    "    <skills>\n",
    "        <technical>\n",
    "            <software>\n",
    "                LIST SOFTWARE SKILLS\n",
    "            </software>\n",
    "            <languages>\n",
    "                LIST PROGRAMMING LANGUAGES\n",
    "            </languages>\n",
    "            <frameworks>\n",
    "                LIST FRAMEWORKS\n",
    "            </frameworks>\n",
    "            <tools>\n",
    "                LIST TECHNICAL TOOLS\n",
    "            </tools>\n",
    "        </technical>\n",
    "        <nontechnical>\n",
    "            LIST NON-TECHNICAL SKILLS\n",
    "        </nontechnical>\n",
    "    </skills>\n",
    "</resume>\n",
    "\n",
    "---\n",
    "\n",
    "You will now be given a resume in plain text. Extract and organize the information as described above.\n",
    "**Resume**:  \n",
    "{resume}\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
